{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Concerts - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Now that you've seen how to scrape a simple website, it's time to again practice those skills on a full-fledged site!\n",
    "\n",
    "In this lab, you'll practice your scraping skills on an online music magazine and events website called Resident Advisor.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "* Create a full scraping pipeline that involves traversing over many pages of a website, dealing with errors and storing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the Website\n",
    "\n",
    "For this lab, you'll be scraping the https://ra.co website. For reproducibility we will use the [Internet Archive](https://archive.org/) Wayback Machine to retrieve a version of this page from March 2019.\n",
    "\n",
    "Start by navigating to the events page [here](https://web.archive.org/web/20210325230938/https://ra.co/events/us/newyork?week=2019-03-30) in your browser. It should look something like this:\n",
    "\n",
    "<img src=\"images/ra_top.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open the Inspect Element Feature\n",
    "\n",
    "Next, open the inspect element feature from your web browser in order to preview the underlying HTML associated with the page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a Function to Scrape all of the Events on the Given Page\n",
    "\n",
    "The function should return a Pandas DataFrame with columns for the `Event_Name`, `Venue`, and `Number_of_Attendees`.\n",
    "\n",
    "Start by importing the relevant libraries, making a request to the relevant URL, and exploring the contents of the response with `BeautifulSoup`. Then fill in the `scrape_events` function with the relevant code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVENTS_PAGE_URL = \"https://web.archive.org/web/20210326225933/https://ra.co/events/us/newyork?week=2019-03-30\"\n",
    "r = requests.get(EVENTS_PAGE_URL)\n",
    "soup = BeautifulSoup(r.content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the container with event listings in it\n",
    "# Some hints are giving along the way\n",
    "\n",
    "# This page is organized somewhat unusually, and many of\n",
    "# the CSS attributes seem auto-generated. We notice that\n",
    "# there is a div with \"events-all\" in its attributes that\n",
    "# looks promising if we use soup.find(), call this events_all_div\n",
    "\n",
    "events_all_div = soup.find('div',attrs={\"data-tracking-id\": \"events-all\"})\n",
    "\n",
    "# The actual content is nested in a ul containing a single\n",
    "# li within that div. Unclear why they are using a \"list\"\n",
    "# concept for one element, but let's go ahead and select it\n",
    "# Call this event_listings and use it to find ul and li in \n",
    "# events_all_div\n",
    "\n",
    "event_listings = events_all_div.find('ul').find('li')\n",
    "\n",
    "\n",
    "# Print out some chunks of the text inside to make sure we\n",
    "# have everything we need in here\n",
    "# For example print the events for March 30th and 31st\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 index: ̸Sat, 30 MarUnterMania IIMary Yuzovskaya, Manni Dee, Umfang, Juana, The Lady MachineTBA - New YorkRARA Tickets457Cocoon New York: Sven Väth, Ilario Alicante, Butch & TaimurSven Vath, Butch, Taimur, Il\n",
      "\n",
      "1 index:  \n",
      "\n",
      "2 index: ̸Sun, 31 MarSunday: Soul SummitNowadaysRARA Tickets132New Dad & Aaron Clark (Honcho)Aaron Clark, New DadAce Hotel3ParadiscoOccupy The DiscoLe Bain3Sunday Soiree: Unknown Showcase (Detroit)Ryan Dahl, H\n"
     ]
    }
   ],
   "source": [
    "# Find a list of events by date within that container\n",
    "\n",
    "# Now we look at what is inside of that event_listings li tag.\n",
    "# Based on looking at the HTML with developer tools, we see\n",
    "# that there are 13 children of that tag, all divs. Each div\n",
    "# is either a container of events on a given date, or empty\n",
    "\n",
    "# Let's create a collection of those divs. recursive=False\n",
    "# means we stop at 1 level below the event_listings li\n",
    "dates = event_listings.findChildren(recursive=False)\n",
    "\n",
    "# Now let's print out the start of the March 30th and March\n",
    "# 31st sections again. This time each is in its own \"date\"\n",
    "# container\n",
    "\n",
    "# March 30th is at the 0 index\n",
    "print(\"0 index:\", dates[0].text[:200])\n",
    "print()\n",
    "# The 1 index is empty. We'll need to skip this later\n",
    "print(\"1 index: \", dates[1].text)\n",
    "print()\n",
    "# March 31st is at the 2 index\n",
    "print(\"2 index:\", dates[2].text[:200])\n",
    "\n",
    "# Now we know we can loop over all of the items in the dates\n",
    "# list of divs to find the dates, although some will be blank\n",
    "# so we'll need to skip them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the date (e.g. Sat, 30 Mar) from one of those containers\n",
    "# Call this first_date\n",
    "\n",
    "# Grabbing just one to practice on\n",
    "first_date = dates[0]\n",
    "\n",
    "# This div contains a div with the date, followed by several uls\n",
    "# containing actual event information\n",
    "\n",
    "# The div with the date happens to have another human-readable\n",
    "# CSS class, so let's use that to select it then grab its text\n",
    "# Call this date, and use class_=sticky header as an argument for\n",
    "# first_date.find\n",
    "date = first_date.find('div', class_='sticky-header').text[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"Box-omzyfs-0 sc-AxjAm jYikCb\" height=\"30\">\n",
      " <div class=\"Box-omzyfs-0 sc-AxjAm faxXyr\" color=\"secondary\" height=\"24\" width=\"24\">\n",
      "  <svg aria-label=\"Ticket\" height=\"100%\" viewbox=\"0 0 24 24\" width=\"100%\">\n",
      "   <g fill=\"none\" fill-rule=\"evenodd\">\n",
      "    <path d=\"M0 0h24v24H0z\" fill=\"none\">\n",
      "    </path>\n",
      "    <path d=\"M8.243 6.827a1 1 0 010-1.414l2.12-2.12a1 1 0 011.415 0l8.485 8.484a1 1 0 010 1.414l-2.12 2.121a1 1 0 01-1.415 0 1 1 0 00-1.415 1.414 1 1 0 010 1.414l-2.12 2.123a1 1 0 01-1.415 0l-8.485-8.486a1 1 0 010-1.414l2.122-2.121a1 1 0 011.414 0 1.001 1.001 0 001.414-1.415zm2-.586a3.002 3.002 0 01-4 4.002l-.829.828 7.07 7.07.829-.828a3.002 3.002 0 014.001-4.001l.828-.828-7.071-7.07-.828.827z\" fill=\"currentColor\">\n",
      "    </path>\n",
      "   </g>\n",
      "  </svg>\n",
      " </div>\n",
      " <a class=\"Link__AnchorWrapper-k7o46r-1 cIDdag\" color=\"secondary\" href=\"/web/20210326225933/https://ra.co/events/1234892#tickets\">\n",
      "  <span class=\"Text-sc-1t0gn2o-0 Link__StyledLink-k7o46r-0 iHZuSI\" color=\"secondary\" font-weight=\"normal\" href=\"/events/1234892#tickets\">\n",
      "   <span class=\"Box-omzyfs-0 kMopVb\" display=\"[object Object]\">\n",
      "    RA\n",
      "   </span>\n",
      "   <span class=\"Box-omzyfs-0 fQMHMH\" display=\"[object Object]\">\n",
      "    RA Tickets\n",
      "   </span>\n",
      "  </span>\n",
      " </a>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "test = first_date.findAll('ul')[0].findAll(attrs={\"height\": 30})[1]\n",
    "print(test.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the name, venue, and number of attendees from one of the\n",
    "# events within that container\n",
    "\n",
    "# As noted previously, the div with information about events on\n",
    "# this date contains several ul tags, each with information about\n",
    "# a specific event. Get a list of them.\n",
    "# (Again this is an odd use of HTML, to have an unordered list\n",
    "# containing a single list item. But we scrape what we find!)\n",
    "first_date_events = first_date.findAll('ul')\n",
    "\n",
    "# Grabbing the first event ul to practice on\n",
    "first_event = first_date_events[0]\n",
    "\n",
    "# Each event ul contains a single h3 with the event name, easy enough\n",
    "name = first_date_events[0].find('h3')\n",
    "\n",
    "# First, get all 1-3 divs that match this description,\n",
    "# where first_event.findAll has attrs={\"height\": 30}\n",
    "# as one of its arguments\n",
    "venue_and_attendees = first_event.findAll(attrs={\"height\": 30})\n",
    "# The venue is the 0th (left-most) div, get its text\n",
    "venue = venue_and_attendees[0].text\n",
    "# The number of attendees is the last div (although it's sometimes\n",
    "# missing), get its text\n",
    "num_attendees = venue_and_attendees[2].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UnterMania II</td>\n",
       "      <td>TBA - New York</td>\n",
       "      <td>Sat, 30 Mar</td>\n",
       "      <td>457.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cocoon New York: Sven Väth, Ilario Alicante, B...</td>\n",
       "      <td>99 Scott Ave</td>\n",
       "      <td>Sat, 30 Mar</td>\n",
       "      <td>407.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Horse Meat Disco - New York Residency</td>\n",
       "      <td>Elsewhere</td>\n",
       "      <td>Sat, 30 Mar</td>\n",
       "      <td>375.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rave: Underground Resistance All Night</td>\n",
       "      <td>Nowadays</td>\n",
       "      <td>Sat, 30 Mar</td>\n",
       "      <td>232.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Believe You Me // Beta Librae, Stephan Kimbel,...</td>\n",
       "      <td>TBA - New York</td>\n",
       "      <td>Sat, 30 Mar</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>A Night at the Baths</td>\n",
       "      <td>C'mon Everybody</td>\n",
       "      <td>Fri, 5 Apr</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Blaqk Audio</td>\n",
       "      <td>Music Hall of Williamsburg</td>\n",
       "      <td>Fri, 5 Apr</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Erik the Lover</td>\n",
       "      <td>Erv's</td>\n",
       "      <td>Fri, 5 Apr</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Wax On Vissions</td>\n",
       "      <td>Starliner</td>\n",
       "      <td>Fri, 5 Apr</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Schimanski &amp; Good Looks present: Mercer</td>\n",
       "      <td>Schimanski</td>\n",
       "      <td>Fri, 5 Apr</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0  \\\n",
       "0                                        UnterMania II   \n",
       "1    Cocoon New York: Sven Väth, Ilario Alicante, B...   \n",
       "2                Horse Meat Disco - New York Residency   \n",
       "3               Rave: Underground Resistance All Night   \n",
       "4    Believe You Me // Beta Librae, Stephan Kimbel,...   \n",
       "..                                                 ...   \n",
       "114                               A Night at the Baths   \n",
       "115                                        Blaqk Audio   \n",
       "116                                     Erik the Lover   \n",
       "117                                    Wax On Vissions   \n",
       "118            Schimanski & Good Looks present: Mercer   \n",
       "\n",
       "                              1            2      3  \n",
       "0                TBA - New York  Sat, 30 Mar  457.0  \n",
       "1                  99 Scott Ave  Sat, 30 Mar  407.0  \n",
       "2                     Elsewhere  Sat, 30 Mar  375.0  \n",
       "3                      Nowadays  Sat, 30 Mar  232.0  \n",
       "4                TBA - New York  Sat, 30 Mar   89.0  \n",
       "..                          ...          ...    ...  \n",
       "114             C'mon Everybody   Fri, 5 Apr    1.0  \n",
       "115  Music Hall of Williamsburg   Fri, 5 Apr    1.0  \n",
       "116                       Erv's   Fri, 5 Apr    1.0  \n",
       "117                   Starliner   Fri, 5 Apr    1.0  \n",
       "118                  Schimanski   Fri, 5 Apr    1.0  \n",
       "\n",
       "[119 rows x 4 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the code below\n",
    "# Make sure you understand it since it will\n",
    "# for the basis of the definition of scrape_events below\n",
    "\n",
    "# Create an empty list to hold results\n",
    "rows = []\n",
    "\n",
    "# Loop over all date containers on the page\n",
    "for date_container in dates:\n",
    "    \n",
    "    # First check if this is one of the empty divs. If it is,\n",
    "    # skip ahead to the next one\n",
    "    if not date_container.text:\n",
    "        continue\n",
    "    \n",
    "    # Same logic as above to extract the date\n",
    "    date = date_container.find(\"div\", class_=\"sticky-header\").text\n",
    "    date = date.strip(\"'̸\")\n",
    "    \n",
    "    # This time, loop over all of the events\n",
    "    events = date_container.findChildren(\"ul\")\n",
    "    for event in events:\n",
    "        \n",
    "        # Same logic as above to extract the name, venue, attendees\n",
    "        name = event.find(\"h3\").text\n",
    "        venue_and_attendees = event.findAll(\"div\", attrs={\"height\": 30})\n",
    "        venue = venue_and_attendees[0].text\n",
    "        try:\n",
    "            num_attendees = int(venue_and_attendees[-1].text)\n",
    "        except ValueError:\n",
    "            num_attendees = np.nan\n",
    "            \n",
    "        # New piece here: appending the new information to rows list\n",
    "        rows.append([name, venue, date, num_attendees])\n",
    "\n",
    "# Make the list of lists into a dataframe and display\n",
    "df = pd.DataFrame(rows)\n",
    "df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring it all together in a function that makes the request, gets the\n",
    "# list of entries from the response, loops over that list to extract the\n",
    "# name, venue, date, and number of attendees for each event, and returns\n",
    "# that list of events as a dataframe\n",
    "\n",
    "def scrape_events(events_page_url):\n",
    "    r = requests.get(events_page_url)\n",
    "    soup = BeautifulSoup(r.content,'html.parser')\n",
    "    events_all_div = soup.find('div',attrs={\"data-tracking-id\": \"events-all\"})\n",
    "    event_listings = events_all_div.find('ul').find('li')\n",
    "    dates = event_listings.findChildren(recursive=False)\n",
    "    rows = []\n",
    "    for date_container in dates:\n",
    "        if not date_container.text:\n",
    "            continue\n",
    "        date = date_container.find(\"div\", class_=\"sticky-header\").text\n",
    "        date = date.strip(\"'̸\")\n",
    "        events = date_container.findChildren(\"ul\")\n",
    "        for event in events:\n",
    "            name = event.find(\"h3\").text\n",
    "            venue_and_attendees = event.findAll(\"div\", attrs={\"height\": 30})\n",
    "            venue = venue_and_attendees[0].text\n",
    "            try:\n",
    "                num_attendees = int(venue_and_attendees[-1].text)\n",
    "            except ValueError:\n",
    "                num_attendees = np.nan\n",
    "            rows.append([name, venue, date, num_attendees])\n",
    "    df = pd.DataFrame(rows)    \n",
    "    df.columns = [\"Event_Name\", \"Venue\", \"Event_Date\", \"Number_of_Attendees\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event_Name</th>\n",
       "      <th>Venue</th>\n",
       "      <th>Event_Date</th>\n",
       "      <th>Number_of_Attendees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UnterMania II</td>\n",
       "      <td>TBA - New York</td>\n",
       "      <td>Sat, 30 Mar</td>\n",
       "      <td>457.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cocoon New York: Sven Väth, Ilario Alicante, B...</td>\n",
       "      <td>99 Scott Ave</td>\n",
       "      <td>Sat, 30 Mar</td>\n",
       "      <td>407.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Horse Meat Disco - New York Residency</td>\n",
       "      <td>Elsewhere</td>\n",
       "      <td>Sat, 30 Mar</td>\n",
       "      <td>375.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rave: Underground Resistance All Night</td>\n",
       "      <td>Nowadays</td>\n",
       "      <td>Sat, 30 Mar</td>\n",
       "      <td>232.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Believe You Me // Beta Librae, Stephan Kimbel,...</td>\n",
       "      <td>TBA - New York</td>\n",
       "      <td>Sat, 30 Mar</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>A Night at the Baths</td>\n",
       "      <td>C'mon Everybody</td>\n",
       "      <td>Fri, 5 Apr</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Blaqk Audio</td>\n",
       "      <td>Music Hall of Williamsburg</td>\n",
       "      <td>Fri, 5 Apr</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Erik the Lover</td>\n",
       "      <td>Erv's</td>\n",
       "      <td>Fri, 5 Apr</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Wax On Vissions</td>\n",
       "      <td>Starliner</td>\n",
       "      <td>Fri, 5 Apr</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Schimanski &amp; Good Looks present: Mercer</td>\n",
       "      <td>Schimanski</td>\n",
       "      <td>Fri, 5 Apr</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Event_Name  \\\n",
       "0                                        UnterMania II   \n",
       "1    Cocoon New York: Sven Väth, Ilario Alicante, B...   \n",
       "2                Horse Meat Disco - New York Residency   \n",
       "3               Rave: Underground Resistance All Night   \n",
       "4    Believe You Me // Beta Librae, Stephan Kimbel,...   \n",
       "..                                                 ...   \n",
       "114                               A Night at the Baths   \n",
       "115                                        Blaqk Audio   \n",
       "116                                     Erik the Lover   \n",
       "117                                    Wax On Vissions   \n",
       "118            Schimanski & Good Looks present: Mercer   \n",
       "\n",
       "                          Venue   Event_Date  Number_of_Attendees  \n",
       "0                TBA - New York  Sat, 30 Mar                457.0  \n",
       "1                  99 Scott Ave  Sat, 30 Mar                407.0  \n",
       "2                     Elsewhere  Sat, 30 Mar                375.0  \n",
       "3                      Nowadays  Sat, 30 Mar                232.0  \n",
       "4                TBA - New York  Sat, 30 Mar                 89.0  \n",
       "..                          ...          ...                  ...  \n",
       "114             C'mon Everybody   Fri, 5 Apr                  1.0  \n",
       "115  Music Hall of Williamsburg   Fri, 5 Apr                  1.0  \n",
       "116                       Erv's   Fri, 5 Apr                  1.0  \n",
       "117                   Starliner   Fri, 5 Apr                  1.0  \n",
       "118                  Schimanski   Fri, 5 Apr                  1.0  \n",
       "\n",
       "[119 rows x 4 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test out your function\n",
    "scrape_events(EVENTS_PAGE_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a Function to Retrieve the URL for the Next Page\n",
    "\n",
    "As you scroll down, there should be a button labeled \"Next Week\" that will take you to the next page of events. Write code to find that button and extract the URL from it.\n",
    "\n",
    "This is a relative path, so make sure you add `https://web.archive.org` to the front to get the URL.\n",
    "\n",
    "![next page](images/ra_next.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/web/20210326225933/https://ra.co/events/us/newyork?week=2019-04-06\n"
     ]
    }
   ],
   "source": [
    "test = soup.find('svg',attrs={\"aria-label\": \"Right arrow\"}).parent.previous_sibling['href']\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://web.archive.org/web/20210326225933/https://ra.co/events/us/newyork?week=2019-04-06'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the button, find the relative path, create the URL for the current `soup`\n",
    "\n",
    "# This is tricky again, since there are not a lot of\n",
    "# human-readable CSS classes\n",
    "\n",
    "# One unique thing we notice is a > icon on the part where\n",
    "# you click to go to the next page. It's an SVG with an \n",
    "# aria-label of \"Right arrow\", this soup.find() will have\n",
    "# attrs={\"aria-label\": \"Right arrow\"} as an argument\n",
    "\n",
    "avg = soup.find('svg',attrs={\"aria-label\": \"Right arrow\"})\n",
    "\n",
    "# That SVG is inside of a div\n",
    "svg_parent = avg.parent\n",
    "\n",
    "# And the tag right before that div (its \"previous sibling\")\n",
    "# is an anchor (link) tag with the path we need\n",
    "link = svg_parent.previous_sibling\n",
    "\n",
    "# Then we can extract the path from that link to build the full URL\n",
    "relative_path = link['href']\n",
    "next_page_url = 'https://web.archive.org' + relative_path\n",
    "next_page_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in this function, to take in the current page's URL and return the\n",
    "# next page's URL\n",
    "def next_page(url):\n",
    "    avg = soup.find('svg',attrs={\"aria-label\": \"Right arrow\"})\n",
    "    svg_parent = avg.parent\n",
    "    link = svg_parent.previous_sibling\n",
    "    relative_path = link['href']\n",
    "    next_page_url = 'https://web.archive.org' + relative_path\n",
    "    return next_page_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://web.archive.org/web/20210326225933/https://ra.co/events/us/newyork?week=2019-04-06'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test out your function\n",
    "next_page(EVENTS_PAGE_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape the Next 500 Events\n",
    "\n",
    "In other words, repeatedly call `scrape_events` and `next_page` until you have assembled a dataframe with at least 500 rows.\n",
    "\n",
    "Display the data sorted by the number of attendees, greatest to least.\n",
    "\n",
    "We recommend adding a brief `time.sleep` call between `requests.get` calls to avoid rate limiting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "overall_df = pd.DataFrame()\n",
    "current_url = EVENTS_PAGE_URL\n",
    "while len(overall_df) < 500:\n",
    "    df = scrape_events(current_url)\n",
    "    overall_df = pd.concat([overall_df,df],axis=0).reset_index(drop=True)\n",
    "    current_url = next_page(current_url)\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event_Name</th>\n",
       "      <th>Venue</th>\n",
       "      <th>Event_Date</th>\n",
       "      <th>Number_of_Attendees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>Zero presents... The Masquerade</td>\n",
       "      <td>The 1896</td>\n",
       "      <td>Sat, 6 Apr</td>\n",
       "      <td>919.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>Zero presents... The Masquerade</td>\n",
       "      <td>The 1896</td>\n",
       "      <td>Sat, 6 Apr</td>\n",
       "      <td>919.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>Zero presents... The Masquerade</td>\n",
       "      <td>The 1896</td>\n",
       "      <td>Sat, 6 Apr</td>\n",
       "      <td>919.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Zero presents... The Masquerade</td>\n",
       "      <td>The 1896</td>\n",
       "      <td>Sat, 6 Apr</td>\n",
       "      <td>919.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>Stavroz live! presented by Zero</td>\n",
       "      <td>The Williamsburg Hotel</td>\n",
       "      <td>Fri, 12 Apr</td>\n",
       "      <td>481.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Petra, Matthusen &amp; Lang, White &amp; Pitsiokos, an...</td>\n",
       "      <td>H0L0</td>\n",
       "      <td>Sat, 30 Mar</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Bonsai: West1ne</td>\n",
       "      <td>Sunnyvale</td>\n",
       "      <td>Sat, 6 Apr</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>Bonsai: West1ne</td>\n",
       "      <td>Sunnyvale</td>\n",
       "      <td>Sat, 6 Apr</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>Bonsai: West1ne</td>\n",
       "      <td>Sunnyvale</td>\n",
       "      <td>Sat, 6 Apr</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>Bonsai: West1ne</td>\n",
       "      <td>Sunnyvale</td>\n",
       "      <td>Sat, 6 Apr</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>583 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Event_Name  \\\n",
       "351                    Zero presents... The Masquerade   \n",
       "467                    Zero presents... The Masquerade   \n",
       "235                    Zero presents... The Masquerade   \n",
       "119                    Zero presents... The Masquerade   \n",
       "324                    Stavroz live! presented by Zero   \n",
       "..                                                 ...   \n",
       "39   Petra, Matthusen & Lang, White & Pitsiokos, an...   \n",
       "154                                    Bonsai: West1ne   \n",
       "270                                    Bonsai: West1ne   \n",
       "386                                    Bonsai: West1ne   \n",
       "502                                    Bonsai: West1ne   \n",
       "\n",
       "                      Venue   Event_Date  Number_of_Attendees  \n",
       "351                The 1896   Sat, 6 Apr                919.0  \n",
       "467                The 1896   Sat, 6 Apr                919.0  \n",
       "235                The 1896   Sat, 6 Apr                919.0  \n",
       "119                The 1896   Sat, 6 Apr                919.0  \n",
       "324  The Williamsburg Hotel  Fri, 12 Apr                481.0  \n",
       "..                      ...          ...                  ...  \n",
       "39                     H0L0  Sat, 30 Mar                  NaN  \n",
       "154               Sunnyvale   Sat, 6 Apr                  NaN  \n",
       "270               Sunnyvale   Sat, 6 Apr                  NaN  \n",
       "386               Sunnyvale   Sat, 6 Apr                  NaN  \n",
       "502               Sunnyvale   Sat, 6 Apr                  NaN  \n",
       "\n",
       "[583 rows x 4 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_df.sort_values('Number_of_Attendees', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "Congratulations! In this lab, you successfully developed a pipeline to scrape a website for concert event information!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
